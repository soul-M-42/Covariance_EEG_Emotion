
defaults:
  - _self_
  # - data_1: SEEDV_small
  - data@data_0: SEEDIV
  - data@data_1: SEED
  - data@data_2: FACED_blink_only
  # - data_2: FACED_blink_only_small
  # - data_2: SEEDV_small
  - data@data_val: SEEDV
  # - data_2: FACED_blink_only_small
  # - data_2: SEEDV_small
  # WARNING: REMEMBER TO CHANGE train.n_fold WHEN CHANGE DATASET/DATASET_SMALL
  # SMALL: fold=3
  # NORMAL: fold=16
  - model: cnn_att

seed: 7

channel_encoder:
  model: 'replace'
  patch_size: 32
  hidden_dim: 128
  out_dim: 4
  depth: 1
  patch_stride: 4
  drop_path: 0.1
  n_filter: 16
  filterLen: 10
  n_heads: 4

align:
  device: gpu
  factor: 1.0
  n_channel_uni: 60
  to_riem: False
  proto_loss: False
  align_loss: True
  clisa_loss: True
  MLP_loss: False

log:
  is_logger: True
  logpath: 'log_trinity'
  # logpath: 'log'
  # logpath: 'log'
  run: 4
  proj_name: cov_align
  # CDA for Cross Dataset Align

  exp_name: ${log.proj_name}

  # cp_dir: ext/mlp cp save path, different dataset will be saved in separate subfolder 
  cp_dir: '/mnt/data/model_weights/DUAL_cp'   

train:
  n_fold: 1
  n_pairs: 1024
  gpus: [0]
  iftest: False
  valid_method: 4
  reverse: True
  # n_subs: ${data.n_subs}
  lr: 5e-4
  wd: 0.0001
  loss_temp: 0.07
  max_epochs: 20
  min_epochs: 1
  patience: 30
  restart_times: ${train.max_epochs}  # scheduler
  val_sub_p: 0.8
  grad_accumulation: 1
  num_workers: 127

finetune:
  n_pairs: 1024
  gpus: [0]
  iftest: False
  valid_method: 4
  # n_subs: ${data.n_subs}
  lr: 5e-4
  wd: 0.010
  loss_temp: 0.07
  max_epochs: 20
  min_epochs: 2
  patience: 30
  restart_times: ${train.max_epochs}  # scheduler
  val_sub_p: 0.8
  grad_accumulation: 1
  num_workers: 127
  align: True



mlp:
  # fea_dim: 256 #${model.n_timeFilters*model.n_msFilters*4}
  hidden_dim: 128
  out_dim: ${data_val.n_class}
  lr: 0.0005  #0.0005
  wd: 0.0022   #0.001-0.005
  max_epochs: 8
  min_epochs: 2
  patience: 30
  gpus: ${train.gpus}
  num_workers: ${train.num_workers}
  batch_size: 512

ext_fea:
  finetune: False
  normTrain: True
  batch_size: 256
  mode: 'me'
  rn_decay: 0.990
  use_pretrain: True


hydra:
  job:
    chdir: false
  run:
    dir: ./clisa_run/${log.proj_name}/${now:%Y-%m-%d}/${now:%H-%M-%S}_run${log.run}